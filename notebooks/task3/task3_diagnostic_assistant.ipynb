{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3: AI Diagnostic Assistant\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "Before running this notebook, ensure that all necessary dependencies are installed and required directories are created by executing the setup script:\n",
        "\n",
        "```bash\n",
        "bash scripts/setup.sh\n",
        "```\n",
        "\n",
        "Alternatively, manually install dependencies with `pip install -r requirements.txt` and create the `outputs/models/` and `outputs/vectorstore/` directories. For detailed setup instructions, refer to the **Setup** section in `docs/task3_implementation_plan.md`.\n",
        "\n",
        "## Objective\n",
        "The goal of this task is to build an AI-powered diagnostic assistant that can help users understand their symptoms and provide insights about cancer-related health data. The assistant integrates two tools:\n",
        "- **Tool 1**: Symptom Checker - Uses RAG (Retrieval-Augmented Generation) with ChromaDB to provide disease information and precautions based on user symptoms\n",
        "- **Tool 2**: Cancer Analysis - Analyzes breast cancer data patterns using sequential pattern mining insights\n",
        "\n",
        "## Overview\n",
        "This notebook implements:\n",
        "1. ML Model Training & Vocabulary Export (Phase 1)\n",
        "2. Knowledge Base Setup with ChromaDB (Phase 2)\n",
        "3. Demonstration of the ProjectAssistant (Phase 4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 1: ML Model Training & Vocabulary Export\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Setup and Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Add project root to Python path\n",
        "project_root = Path().resolve().parent.parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "print(\"Libraries imported successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Data Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Shape: (4920, 18)\n",
            "\n",
            "First few rows:\n",
            "            Disease   Symptom_1              Symptom_2              Symptom_3  \\\n",
            "0  Fungal infection     itching              skin_rash   nodal_skin_eruptions   \n",
            "1  Fungal infection   skin_rash   nodal_skin_eruptions    dischromic _patches   \n",
            "2  Fungal infection     itching   nodal_skin_eruptions    dischromic _patches   \n",
            "3  Fungal infection     itching              skin_rash    dischromic _patches   \n",
            "4  Fungal infection     itching              skin_rash   nodal_skin_eruptions   \n",
            "\n",
            "              Symptom_4 Symptom_5 Symptom_6 Symptom_7 Symptom_8 Symptom_9  \\\n",
            "0   dischromic _patches       NaN       NaN       NaN       NaN       NaN   \n",
            "1                   NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2                   NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "3                   NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "4                   NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "\n",
            "  Symptom_10 Symptom_11 Symptom_12 Symptom_13 Symptom_14 Symptom_15  \\\n",
            "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "2        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "3        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "4        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "\n",
            "  Symptom_16 Symptom_17  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "\n",
            "Column names:\n",
            "['Disease', 'Symptom_1', 'Symptom_2', 'Symptom_3', 'Symptom_4', 'Symptom_5', 'Symptom_6', 'Symptom_7', 'Symptom_8', 'Symptom_9', 'Symptom_10', 'Symptom_11', 'Symptom_12', 'Symptom_13', 'Symptom_14', 'Symptom_15', 'Symptom_16', 'Symptom_17']\n",
            "\n",
            "==================================================\n",
            "Preprocessing Results\n",
            "==================================================\n",
            "\n",
            "Sample symptoms_text:\n",
            "itching skin_rash nodal_skin_eruptions dischromic_patches nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "\n",
            "Number of unique diseases: 41\n",
            "\n",
            "Example - Disease: Fungal infection, Symptoms: itching skin_rash nodal_skin_eruptions dischromic_patches nan nan nan nan nan nan nan nan nan nan nan nan nan\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess the dataset\n",
        "DATA_PATH = project_root / 'data' / 'dataset.csv'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nColumn names:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Combine symptom columns into a single text field\n",
        "symptom_cols = [f'Symptom_{i}' for i in range(1, 18)]\n",
        "\n",
        "# Define function to clean string values only (treat non-strings as None)\n",
        "def clean_symptom_value(value):\n",
        "    \"\"\"Clean symptom value: trim and normalize underscores for strings only, leave non-strings as None.\"\"\"\n",
        "    if not isinstance(value, str):\n",
        "        return None\n",
        "    # Strip whitespace and normalize underscores (remove spaces around underscores, normalize multiple underscores)\n",
        "    import re\n",
        "    cleaned = value.strip()\n",
        "    cleaned = re.sub(r'\\s+_\\s+', '_', cleaned)  # Remove spaces around underscores\n",
        "    cleaned = re.sub(r'\\s+_', '_', cleaned)  # Remove spaces before underscores\n",
        "    cleaned = re.sub(r'_\\s+', '_', cleaned)  # Remove spaces after underscores\n",
        "    cleaned = cleaned.strip('_')  # Remove leading/trailing underscores\n",
        "    return cleaned if cleaned else None\n",
        "\n",
        "# Apply cleaning function to each symptom column (only processes strings, leaves NaN as None)\n",
        "for col in symptom_cols:\n",
        "    df[col] = df[col].apply(clean_symptom_value)\n",
        "\n",
        "# Build symptoms_text from symptom_cols by selecting only non-null entries (without prior astype(str))\n",
        "def build_symptoms_text(row):\n",
        "    \"\"\"Build symptoms_text from symptom columns, selecting only non-null entries without converting NaN to strings.\"\"\"\n",
        "    symptoms = []\n",
        "    for val in row[symptom_cols]:\n",
        "        if pd.notna(val) and val is not None and isinstance(val, str) and val.strip():\n",
        "            symptoms.append(val)\n",
        "    return ' '.join(symptoms)\n",
        "\n",
        "df['symptoms_text'] = df.apply(build_symptoms_text, axis=1)\n",
        "\n",
        "# Clean up multiple spaces in symptoms_text\n",
        "df['symptoms_text'] = df['symptoms_text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "# Drop rows with empty symptoms_text\n",
        "df = df[df['symptoms_text'].notna() & (df['symptoms_text'].str.strip() != '')].copy()\n",
        "\n",
        "# Normalize Disease column: strip whitespace\n",
        "df['Disease'] = df['Disease'].str.strip()\n",
        "\n",
        "# Prepare features and target\n",
        "X = df['symptoms_text']\n",
        "y = df['Disease']\n",
        "\n",
        "# Display preprocessing results\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Preprocessing Results\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nSample symptoms_text:\")\n",
        "print(X.iloc[0])\n",
        "print(f\"\\nNumber of unique diseases: {y.nunique()}\")\n",
        "print(f\"\\nExample - Disease: {y.iloc[0]}, Symptoms: {X.iloc[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "Model training complete.\n",
            "\n",
            "Model Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "(vertigo) Paroymsal  Positional Vertigo       1.00      1.00      1.00        18\n",
            "                                   AIDS       1.00      1.00      1.00        30\n",
            "                                   Acne       1.00      1.00      1.00        24\n",
            "                    Alcoholic hepatitis       1.00      1.00      1.00        25\n",
            "                                Allergy       1.00      1.00      1.00        24\n",
            "                              Arthritis       1.00      1.00      1.00        23\n",
            "                       Bronchial Asthma       1.00      1.00      1.00        33\n",
            "                   Cervical spondylosis       1.00      1.00      1.00        23\n",
            "                            Chicken pox       1.00      1.00      1.00        21\n",
            "                    Chronic cholestasis       1.00      1.00      1.00        15\n",
            "                            Common Cold       1.00      1.00      1.00        23\n",
            "                                 Dengue       1.00      1.00      1.00        26\n",
            "                               Diabetes       1.00      1.00      1.00        21\n",
            "           Dimorphic hemmorhoids(piles)       1.00      1.00      1.00        29\n",
            "                          Drug Reaction       1.00      1.00      1.00        24\n",
            "                       Fungal infection       1.00      1.00      1.00        19\n",
            "                                   GERD       1.00      1.00      1.00        28\n",
            "                        Gastroenteritis       1.00      1.00      1.00        25\n",
            "                           Heart attack       1.00      1.00      1.00        23\n",
            "                            Hepatitis B       1.00      1.00      1.00        27\n",
            "                            Hepatitis C       1.00      1.00      1.00        26\n",
            "                            Hepatitis D       1.00      1.00      1.00        23\n",
            "                            Hepatitis E       1.00      1.00      1.00        29\n",
            "                           Hypertension       1.00      1.00      1.00        25\n",
            "                        Hyperthyroidism       1.00      1.00      1.00        24\n",
            "                           Hypoglycemia       1.00      1.00      1.00        26\n",
            "                         Hypothyroidism       1.00      1.00      1.00        21\n",
            "                               Impetigo       1.00      1.00      1.00        24\n",
            "                               Jaundice       1.00      1.00      1.00        19\n",
            "                                Malaria       1.00      1.00      1.00        22\n",
            "                               Migraine       1.00      1.00      1.00        25\n",
            "                        Osteoarthristis       1.00      1.00      1.00        22\n",
            "           Paralysis (brain hemorrhage)       1.00      1.00      1.00        24\n",
            "                    Peptic ulcer diseae       1.00      1.00      1.00        17\n",
            "                              Pneumonia       1.00      1.00      1.00        28\n",
            "                              Psoriasis       1.00      1.00      1.00        22\n",
            "                           Tuberculosis       1.00      1.00      1.00        25\n",
            "                                Typhoid       1.00      1.00      1.00        19\n",
            "                Urinary tract infection       1.00      1.00      1.00        26\n",
            "                         Varicose veins       1.00      1.00      1.00        22\n",
            "                            hepatitis A       1.00      1.00      1.00        34\n",
            "\n",
            "                               accuracy                           1.00       984\n",
            "                              macro avg       1.00      1.00      1.00       984\n",
            "                           weighted avg       1.00      1.00      1.00       984\n",
            "\n",
            "\n",
            "Vocabulary exported to: /Users/bytedance/GitHub/SC4020-Group-Project-2/outputs/models/symptom_vocabulary.json\n",
            "Vocabulary size: 134 unique symptom tokens\n",
            "Trained model saved to: /Users/bytedance/GitHub/SC4020-Group-Project-2/outputs/models/disease_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the ML pipeline\n",
        "disease_pipeline = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the model...\")\n",
        "disease_pipeline.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = disease_pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Export the vocabulary\n",
        "vocabulary = disease_pipeline.named_steps['vectorizer'].get_feature_names_out()\n",
        "vocabulary_list = vocabulary.tolist()\n",
        "\n",
        "vocab_path = project_root / 'outputs' / 'models' / 'symptom_vocabulary.json'\n",
        "vocab_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "with open(vocab_path, 'w') as f:\n",
        "    json.dump(vocabulary_list, f, indent=2)\n",
        "\n",
        "print(f\"\\nVocabulary exported to: {vocab_path}\")\n",
        "print(f\"Vocabulary size: {len(vocabulary_list)} unique symptom tokens\")\n",
        "\n",
        "# Save the trained model\n",
        "model_path = project_root / 'outputs' / 'models' / 'disease_model.pkl'\n",
        "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "joblib.dump(disease_pipeline, model_path)\n",
        "\n",
        "print(f\"Trained model saved to: {model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 2: Knowledge Base Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Setup and Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "`np.float_` was removed in the NumPy 2.0 release. Use `np.float64` instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/SC4020-Group-Project-2/venv/lib/python3.13/site-packages/chromadb/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client \u001b[38;5;28;01mas\u001b[39;00m ClientCreator\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdminClient \u001b[38;5;28;01mas\u001b[39;00m AdminClientCreator\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masync_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncClient \u001b[38;5;28;01mas\u001b[39;00m AsyncClientCreator\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/SC4020-Group-Project-2/venv/lib/python3.13/site-packages/chromadb/api/__init__.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moverrides\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_DATABASE, DEFAULT_TENANT\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mCollection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Collection\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     CollectionMetadata,\n\u001b[32m     10\u001b[39m     Documents,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     WhereDocument,\n\u001b[32m     24\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Component, Settings\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/SC4020-Group-Project-2/venv/lib/python3.13/site-packages/chromadb/api/models/Collection.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Optional, Union\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mCollectionCommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CollectionCommon\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     URI,\n\u001b[32m      7\u001b[39m     CollectionMetadata,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     WhereDocument,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/SC4020-Group-Project-2/venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muuid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UUID\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membedding_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mef\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     URI,\n\u001b[32m     17\u001b[39m     CollectionMetadata,\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     validate_where_document,\n\u001b[32m     52\u001b[39m )\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# TODO: We should rename the types in chromadb.types to be Models where\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# appropriate. This will help to distinguish between manipulation objects\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# which are essentially API views. And the actual data models which are\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# stored / retrieved / transmitted.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/SC4020-Group-Project-2/venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions.py:7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_property\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtenacity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stop_after_attempt, wait_random, retry, retry_if_exception\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     Document,\n\u001b[32m      9\u001b[39m     Documents,\n\u001b[32m     10\u001b[39m     Embedding,\n\u001b[32m     11\u001b[39m     Image,\n\u001b[32m     12\u001b[39m     Images,\n\u001b[32m     13\u001b[39m     EmbeddingFunction,\n\u001b[32m     14\u001b[39m     Embeddings,\n\u001b[32m     15\u001b[39m     is_image,\n\u001b[32m     16\u001b[39m     is_document,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BytesIO\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/SC4020-Group-Project-2/venv/lib/python3.13/site-packages/chromadb/api/types.py:104\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Documents, target)\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# Images\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m ImageDType = Union[np.uint, np.int_, \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat_\u001b[49m]\n\u001b[32m    105\u001b[39m Image = NDArray[ImageDType]\n\u001b[32m    106\u001b[39m Images = List[Image]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/SC4020-Group-Project-2/venv/lib/python3.13/site-packages/numpy/__init__.py:781\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
            "\u001b[31mAttributeError\u001b[39m: `np.float_` was removed in the NumPy 2.0 release. Use `np.float64` instead."
          ]
        }
      ],
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Define project_root for Phase 2 (allows Phase 2 to run independently)\n",
        "project_root = Path().resolve().parent.parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"SentenceTransformer model loaded successfully.\")\n",
        "print(f\"Embedding dimension: {embedding_model.get_sentence_embedding_dimension()}\")\n",
        "\n",
        "print(\"Libraries imported successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Load Disease Information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load disease descriptions and precautions\n",
        "DESCRIPTION_PATH = project_root / 'data' / 'symptom_Description.csv'\n",
        "PRECAUTION_PATH = project_root / 'data' / 'symptom_precaution.csv'\n",
        "\n",
        "# Load disease descriptions\n",
        "descriptions_df = pd.read_csv(DESCRIPTION_PATH)\n",
        "print(f\"Descriptions shape: {descriptions_df.shape}\")\n",
        "print(descriptions_df.head())\n",
        "\n",
        "# Load disease precautions\n",
        "precautions_df = pd.read_csv(PRECAUTION_PATH)\n",
        "print(f\"\\nPrecautions shape: {precautions_df.shape}\")\n",
        "print(precautions_df.head())\n",
        "\n",
        "# Data cleaning: strip whitespace from Disease column\n",
        "descriptions_df['Disease'] = descriptions_df['Disease'].str.strip()\n",
        "precautions_df['Disease'] = precautions_df['Disease'].str.strip()\n",
        "\n",
        "# Normalize disease names using correction map to fix typos and mismatches\n",
        "def normalize_disease_name(name):\n",
        "    \"\"\"Normalize disease names to fix typos and inconsistencies.\"\"\"\n",
        "    # Correction map for known typos/mismatches\n",
        "    correction_map = {\n",
        "        'hemmorhoids': 'hemorrhoids',  # Fix typo: hemmorhoids -> hemorrhoids\n",
        "        'Paroymsal': 'Paroxysmal',  # Fix typo: Paroymsal -> Paroxysmal\n",
        "    }\n",
        "    \n",
        "    normalized = name\n",
        "    for typo, correct in correction_map.items():\n",
        "        if typo in normalized:\n",
        "            normalized = normalized.replace(typo, correct)\n",
        "    return normalized\n",
        "\n",
        "# Apply normalization to both dataframes\n",
        "descriptions_df['Disease'] = descriptions_df['Disease'].apply(normalize_disease_name)\n",
        "precautions_df['Disease'] = precautions_df['Disease'].apply(normalize_disease_name)\n",
        "\n",
        "# Verify data alignment after normalization\n",
        "print(f\"\\nAfter normalization:\")\n",
        "print(f\"Unique diseases in descriptions: {descriptions_df['Disease'].nunique()}\")\n",
        "print(f\"Unique diseases in precautions: {precautions_df['Disease'].nunique()}\")\n",
        "\n",
        "desc_diseases = set(descriptions_df['Disease'])\n",
        "prec_diseases = set(precautions_df['Disease'])\n",
        "mismatches_desc = desc_diseases - prec_diseases\n",
        "mismatches_prec = prec_diseases - desc_diseases\n",
        "\n",
        "if mismatches_desc:\n",
        "    print(f\"Diseases only in descriptions: {mismatches_desc}\")\n",
        "if mismatches_prec:\n",
        "    print(f\"Diseases only in precautions: {mismatches_prec}\")\n",
        "if not mismatches_desc and not mismatches_prec:\n",
        "    print(\"✓ All diseases match between descriptions and precautions files.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Initialize ChromaDB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ChromaDB persistent client\n",
        "VECTORSTORE_PATH = project_root / 'outputs' / 'vectorstore' / 'chroma_db'\n",
        "\n",
        "# Create the vectorstore directory\n",
        "VECTORSTORE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Vectorstore directory: {VECTORSTORE_PATH}\")\n",
        "\n",
        "# Initialize ChromaDB persistent client\n",
        "chroma_client = chromadb.PersistentClient(path=str(VECTORSTORE_PATH))\n",
        "print(\"ChromaDB persistent client initialized.\")\n",
        "\n",
        "# Define embedding function for the collection\n",
        "def embed_function(texts):\n",
        "    \"\"\"Embedding function that wraps SentenceTransformer encode.\"\"\"\n",
        "    return embedding_model.encode(texts).tolist()\n",
        "\n",
        "# Create or get the collection with embedding function\n",
        "collection = chroma_client.get_or_create_collection(\n",
        "    name=\"disease_info\",\n",
        "    embedding_function=embed_function\n",
        ")\n",
        "print(f\"Collection 'disease_info' ready. Current document count: {collection.count()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Populate Vector Database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge descriptions and precautions\n",
        "merged_df = pd.merge(descriptions_df, precautions_df, on='Disease', how='inner')\n",
        "print(f\"Merged dataframe shape: {merged_df.shape}\")\n",
        "print(merged_df.head())\n",
        "\n",
        "# Assert that merged row count equals the number of unique diseases\n",
        "unique_disease_count = descriptions_df['Disease'].nunique()\n",
        "merged_row_count = len(merged_df)\n",
        "assert merged_row_count == unique_disease_count, f\"Merge failed: expected {unique_disease_count} rows, got {merged_row_count}. Check for remaining disease name mismatches.\"\n",
        "print(f\"\\n✓ Merge successful: {merged_row_count} rows match {unique_disease_count} unique diseases.\")\n",
        "\n",
        "# Create combined documents\n",
        "def create_document(row):\n",
        "    description = row['Description']\n",
        "    precautions = [row[f'Precaution_{i}'] for i in range(1, 5) if pd.notna(row[f'Precaution_{i}'])]\n",
        "    precautions_text = ', '.join(precautions) if precautions else 'No specific precautions listed'\n",
        "    return f\"Disease: {row['Disease']}\\n\\nDescription: {description}\\n\\nPrecautions: {precautions_text}\"\n",
        "\n",
        "merged_df['document'] = merged_df.apply(create_document, axis=1)\n",
        "print(\"\\nSample document:\")\n",
        "print(merged_df['document'].iloc[0])\n",
        "\n",
        "# Create stable IDs from disease names (slugify)\n",
        "import re\n",
        "def slugify_disease_name(name):\n",
        "    \"\"\"Create a stable ID from disease name.\"\"\"\n",
        "    # Convert to lowercase, replace spaces and special chars with underscores\n",
        "    slug = name.lower()\n",
        "    slug = re.sub(r'[^\\w\\s-]', '', slug)  # Remove special chars except spaces and hyphens\n",
        "    slug = re.sub(r'[-\\s]+', '_', slug)  # Replace spaces and hyphens with underscores\n",
        "    slug = slug.strip('_')  # Remove leading/trailing underscores\n",
        "    return f\"disease_{slug}\"\n",
        "\n",
        "# Prepare data for ChromaDB\n",
        "documents = merged_df['document'].tolist()\n",
        "ids = [slugify_disease_name(disease) for disease in merged_df['Disease']]\n",
        "metadatas = [{'disease': disease} for disease in merged_df['Disease']]\n",
        "print(f\"\\nPrepared {len(documents)} documents for embedding.\")\n",
        "\n",
        "# Clear existing collection to avoid duplicates (idempotent operation)\n",
        "if collection.count() > 0:\n",
        "    print(f\"Clearing existing collection ({collection.count()} documents)...\")\n",
        "    chroma_client.delete_collection(\"disease_info\")\n",
        "    collection = chroma_client.create_collection(\n",
        "        name=\"disease_info\",\n",
        "        embedding_function=embed_function\n",
        "    )\n",
        "    print(\"Collection cleared and recreated.\")\n",
        "\n",
        "# Add documents to ChromaDB (embeddings will be generated automatically by the registered embedding_function)\n",
        "collection.add(documents=documents, ids=ids, metadatas=metadatas)\n",
        "print(f\"Successfully added {len(documents)} documents to ChromaDB collection.\")\n",
        "print(f\"Final collection count: {collection.count()}\")\n",
        "\n",
        "# Test the vectorstore using query_texts (works with embedding function)\n",
        "test_results = collection.query(query_texts=['fever and cough'], n_results=3)\n",
        "print(\"\\nTest query results:\")\n",
        "for i, (doc, metadata) in enumerate(zip(test_results['documents'][0], test_results['metadatas'][0])):\n",
        "    print(f\"{i+1}. {metadata['disease']}: {doc[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 4: Demonstration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Setup and Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to Python path\n",
        "project_root = Path().resolve().parent.parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Import the ProjectAssistant class\n",
        "from scripts.task3_app import ProjectAssistant\n",
        "\n",
        "print(\"ProjectAssistant imported successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Initialize the Assistant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Initialize ProjectAssistant\n",
        "# assistant = ProjectAssistant()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Test Symptom Checker (Tool 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Test symptom checker queries\n",
        "# Example queries:\n",
        "# - \"I have fever and cough\"\n",
        "# - \"What diseases cause fatigue and headache?\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Test Cancer Analysis (Tool 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Test cancer analysis queries\n",
        "# Example queries:\n",
        "# - \"Tell me about breast cancer patterns\"\n",
        "# - \"What patterns indicate malignant cases?\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Test Router Behavior\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Test router behavior with out-of-scope queries\n",
        "# Example queries:\n",
        "# - \"What's the weather today?\"\n",
        "# - \"Tell me a joke\"\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
