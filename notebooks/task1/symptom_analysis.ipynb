{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1: Symptom Co-occurrence Analysis\n",
        "\n",
        "## Objective\n",
        "The goal of this task is to analyse the co-occurrence patterns of different symptoms within disease profiles. Specifically, the task aims to identify combinations of symptoms that frequently appear together in the same disease.\n",
        "\n",
        "## Method\n",
        "Implement the Apriori algorithm to analyse the Disease Symptom dataset, identifying common combinations of symptoms that frequently co-occur within the same disease profile.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to Python path to import custom modules\n",
        "project_root = Path().resolve().parent.parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "from src.processors.symptom_data_processor import SymptomDataProcessor\n",
        "from src.analysis.symptom_pattern_miner import SymptomPatternMiner\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Libraries and modules imported successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the path to the dataset using the project_root variable\n",
        "# This ensures the path is always correct, regardless of where the notebook is run\n",
        "DATA_PATH = project_root / 'data' / 'dataset.csv'\n",
        "\n",
        "# Initialize and run the data processor\n",
        "processor = SymptomDataProcessor(data_path=DATA_PATH)\n",
        "transactions = processor.process_data()\n",
        "\n",
        "print(f\"Successfully processed {len(transactions)} transactions.\")\n",
        "print(\"Example transaction:\", transactions[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Apriori Algorithm and Association Rule Mining\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the pattern miner.\n",
        "# NOTE: A `min_support` of 0.01 is too low for this dataset and will likely cause a memory error, crashing the kernel.\n",
        "# A value of 0.02 or higher is recommended for stable performance.\n",
        "miner = SymptomPatternMiner(transactions, min_support=0.02)\n",
        "\n",
        "# Mine for frequent itemsets\n",
        "frequent_itemsets = miner.mine_frequent_itemsets()\n",
        "\n",
        "# Generate association rules with a minimum confidence of 50%\n",
        "rules = miner.generate_association_rules(metric=\"confidence\", min_threshold=0.5)\n",
        "\n",
        "# --- Save Results to CSV ---\n",
        "# This allows the analysis section to load pre-computed results,\n",
        "# either from this run or from a previous run of the `symptom_analysis.py` script.\n",
        "output_dir = project_root / 'outputs'\n",
        "output_dir.mkdir(exist_ok=True) # Ensure the directory exists\n",
        "\n",
        "itemsets_path = output_dir / 'frequent_itemsets.csv'\n",
        "rules_path = output_dir / 'association_rules.csv'\n",
        "\n",
        "frequent_itemsets.to_csv(itemsets_path, index=False)\n",
        "rules.to_csv(rules_path, index=False)\n",
        "\n",
        "print(\"Frequent itemsets and association rules have been saved to the 'outputs' directory.\")\n",
        "print(f\"Itemsets saved to: {itemsets_path}\")\n",
        "print(f\"Rules saved to: {rules_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load and Analyze Results\n",
        "\n",
        "This section loads the pre-computed results from the `outputs` directory. You can either generate these files by running the cell above, or by running the main analysis script: `python scripts/symptom_analysis.py`.\n",
        "\n",
        "This allows you to separate the time-consuming mining process from the interactive analysis and visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Load Results from CSV ---\n",
        "# Load the frequent itemsets and association rules from the files saved in the 'outputs' directory.\n",
        "\n",
        "itemsets_path = project_root / 'outputs' / 'frequent_itemsets.csv'\n",
        "rules_path = project_root / 'outputs' / 'association_rules.csv'\n",
        "\n",
        "try:\n",
        "    frequent_itemsets_from_csv = pd.read_csv(itemsets_path)\n",
        "    rules_from_csv = pd.read_csv(rules_path)\n",
        "    \n",
        "    print(\"Successfully loaded pre-computed results from CSV files.\")\n",
        "    \n",
        "    print(\"\\nFrequent Itemsets (Top 10):\")\n",
        "    display(frequent_itemsets_from_csv.head(10))\n",
        "    \n",
        "    print(\"\\nAssociation Rules (Top 10):\")\n",
        "    display(rules_from_csv.head(10))\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"CSV files not found. Please run the mining cell above or the `symptom_analysis.py` script first.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explanation of Association Rule Metrics\n",
        "\n",
        "For a rule **\"IF {A} THEN {B}\"**:\n",
        "\n",
        "| Column | Simple Explanation | In Technical Terms |\n",
        "| :--- | :--- | :--- |\n",
        "| **`antecedents`** | The \"IF\" part of the rule. This is symptom set {A}. | `antecedents` |\n",
        "| **`consequents`** | The \"THEN\" part of the rule. This is symptom set {B}. | `consequents` |\n",
        "| **`antecedent support`** | How often symptom {A} appears in the entire dataset. | `support(A)` |\n",
        "| **`consequent support`** | How often symptom {B} appears in the entire dataset. | `support(B)` |\n",
        "| **`support`** | How often {A} and {B} appear **together** in the dataset. | `support(A U B)` |\n",
        "| **`confidence`** | **The rule's reliability.** \"If a patient has {A}, what's the probability they also have {B}?\" Higher is better. | `support(A U B) / support(A)` |\n",
        "| **`lift`** | **The rule's importance.** How much more likely {B} is to appear when {A} is present. `> 1` is good. Higher is better. | `confidence(A->B) / support(B)` |\n",
        "| **`leverage`** | The difference between how often {A} and {B} appear together versus how often they would if they were independent. `> 0` means they appear together more than expected. | `support(A U B) - (support(A) * support(B))` |\n",
        "| **`conviction`** | A measure of the rule's implication. A high value means the consequent {B} is highly dependent on the antecedent {A}. An `inf` (infinity) value is very strong. | `(1 - support(B)) / (1 - confidence(A->B))` |\n",
        "| **`zhangs_metric`** | A more advanced measure of association that ranges from -1 (perfect negative correlation) to +1 (perfect positive correlation). 0 indicates independence. | A value that considers both support and confidence. |\n",
        "| **`kulczynski`** | The average of the two confidence scores (`A->B` and `B->A`). It's a symmetric measure of how strongly the two are related. | `0.5 * (confidence(A->B) + confidence(B->A))` |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This visualization uses the data loaded from the CSV files.\n",
        "import ast\n",
        "\n",
        "# Get top 10 most frequent itemsets from the DataFrame we loaded from the CSV\n",
        "top_itemsets = frequent_itemsets_from_csv.nlargest(10, 'support')\n",
        "\n",
        "# The 'itemsets' column is loaded as a string, e.g., \"frozenset({'fatigue', 'vomiting'})\".\n",
        "# We need to convert this string back into a plottable format.\n",
        "def format_itemset_str(itemset_str):\n",
        "    try:\n",
        "        # Use ast.literal_eval to safely evaluate the string representation\n",
        "        s = ast.literal_eval(itemset_str)\n",
        "        # It's likely a frozenset, so convert to list and join for a clean label\n",
        "        return ', '.join(list(s))\n",
        "    except (ValueError, SyntaxError):\n",
        "        # If something goes wrong, return the original string\n",
        "        return itemset_str\n",
        "\n",
        "# Prepare data for plotting by creating a new, clean string column for the labels\n",
        "top_itemsets['itemsets_str'] = top_itemsets['itemsets'].apply(format_itemset_str)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='support', y='itemsets_str', data=top_itemsets, palette='viridis')\n",
        "plt.title('Top 10 Most Frequent Symptom Combinations')\n",
        "plt.xlabel('Support')\n",
        "plt.ylabel('Symptom Sets')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
